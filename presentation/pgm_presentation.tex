\input{preamble_theme}

% Presentation data
% ====================================================

\title[PGM Project Presentation]{* * * PGM: Final Project Presentation * * * POS-Tagging and NER}
\institute{TU Darmstadt}
\author{C. Biehl, F. Otto, D. Wehner}
\date{\today}
\prefix{PGM}

% BEGIN OF DOCUMENT
% ====================================================

\begin{document}

% Title frame
%______________________________________________________________________
\maketitlepage

% Agenda
%______________________________________________________________________
\begin{frame}{Agenda}
	\tableofcontents
\end{frame}


\section{Task Description}

% The Task
\begin{frame}{Task Description}{}
	\divideTwo{0.59}{
		\begin{itemize}
			\item The task was to use probabilistic graphical models for:
			\begin{itemize}
				\item POS-Tagging (Part-of-Speech Tagging)
				\item Named Entity Recognition (NER)
			\end{itemize}
			\item We used the following models:
			\begin{itemize}
				\item Na\"{i}ve Bayes (baseline model)
				\item HMMs (Hidden Markov models)
				\item CRFs (Conditional Random Fields)
			\end{itemize}
		\end{itemize}
	}{0.39}{
		\begin{figure}
			\fbox{\includegraphics[scale=0.05]{img/bayes_theorem}}
		\end{figure}
	}
\end{frame}


% Part of Speech Tagging
\begin{frame}{Part of Speech Tagging}{}
	\begin{figure}
		\includegraphics[scale=0.4]{img/pos_tagging}
		\caption{Part of speech tagging}
	\end{figure}
\end{frame}


% Named Entity Recognition
\begin{frame}{Part of Speech Tagging}{}
	\begin{figure}
		\includegraphics[scale=0.35]{img/ner}
		\caption{Named entity recognition}
	\end{figure}
\end{frame}

\section{Process and Tools}

% Process and Tools
\begin{frame}{Process and Tools}{}
	\begin{figure}
		\includegraphics[scale=0.4]{img/nlp_pipeline}
		\caption{NLP-Pipeline}
	\end{figure}

	\begin{itemize}
		\item POS tagging is one of the earliest stages in the NLP pipeline and serves as input for most
			downstream tasks
		\item E.\,g. NER: POS tags can be used as a feature 
	\end{itemize}
\end{frame}


\section{Results and Comparison}

% Results
\begin{frame}{Results}{POS Tagging}
	\divideTwo{0.49}{
		\begin{table}[h]
			\scalebox{0.8}{
			\begin{tabular}{| c | c | c |}
				\hline
				\multicolumn{3}{| c |}{\textbf{Na\"{i}ve Bayes} [POS]}
				\\ \hline\hline
				\textbf{Features}		&	\textbf{F1 score}		& 	\textbf{Acc (w / s)}
				\\ \hline\hline
				w, l, s 				& 	0.927				& 	0.927 / 0.240
				\\ \hline
				w, l, s, uwf				&	0.928				&	0.928 / 0.241
				\\ \hline
				w, l, s, bf 				& 	0.957 				&	0.957 / 0.467
				\\ \hline
				w, l, s, uwf, bf			& 	0.949 				& 	0.949 / 0.369
				\\ \hline
			\end{tabular}}
		\end{table}
	}{0.49}{
		\begin{table}[h]
			\scalebox{0.8}{
			\begin{tabular}{| c | c | c |}
				\hline
				\multicolumn{3}{| c |}{\textbf{HMM} [POS]}
				\\ \hline\hline
				\textbf{Features}		&	\textbf{F1 score}		& 	\textbf{Acc (w / s)}
				\\ \hline\hline
				word sequence 		&	0.837 				& 	0.837 / 0.496
				\\ \hline
			\end{tabular}}
		\end{table}
	}
	\tiny \textbf{Legend:} \\
	\textbf{w}: word, \textbf{l}: lowercase word, \textbf{s}: stem, \textbf{uwf}: unknown word features,
	\textbf{bf}: bigram features
\end{frame}


% Results (Ctd.)
\begin{frame}{Results (Ctd.)}{POS Tagging}
	\begin{table}[h]
		\scalebox{1.0}{
		\begin{tabular}{| c | c | c |}
			\hline
			\multicolumn{3}{| c |}{\textbf{CRF} [POS]}
			\\ \hline\hline
			\textbf{Features}		&	\textbf{F1 score}		& 	\textbf{Acc (w / s)}
			\\ \hline\hline
			w, l, s 				& 						& 	
			\\ \hline
			w, l, s, uwf				&	0.980				&	0.980 / 0.749
			\\ \hline
			w, l, s, bf 				& 			 			&	
			\\ \hline
			w, l, s, uwf, bf			& 	0.985 				& 	0.985 / 0.740
			\\ \hline
		\end{tabular}}
	\end{table}
	\tiny \textbf{Legend:} \\
	\textbf{w}: word, \textbf{l}: lowercase word, \textbf{s}: stem, \textbf{uwf}: unknown word features,
	\textbf{bf}: bigram features
\end{frame}


% Confusion Matrix CRF (all features)
\begin{frame}{Confusion Matrix CRF (all features)}{}
	\begin{figure}
		\includegraphics[scale=0.08]{img/cm_pos}
		\caption{Named entity recognition}
	\end{figure}
\end{frame}


% Results (Ctd.)
\begin{frame}{Results (Ctd.)}{Named Entity Recognition}
	\divideTwo{0.49}{
		\begin{table}[h]
			\scalebox{0.8}{
			\begin{tabular}{| c | c | c | }
				\hline
				\multicolumn{3}{| c |}{\textbf{Na\"{i}ve Bayes} [NER]}
				\\ \hline\hline
				\textbf{Features}		&	\textbf{F1 score}		& 	\textbf{Acc (w / s)}
				\\ \hline\hline
				w, l, s				& 	0.921				& 	0.921 / 0.262
				\\ \hline
				w, l, s, uwf				&	0.922				&	0.922 / 0.237
				\\ \hline
				w, l, s, uwf, pos			& 	0.921 				&	0.921 / 0.240
				\\ \hline
				w, l, s, uwf, pos, bf		& 	0.929 				& 	0.929 / 0.288
				\\ \hline
			\end{tabular}}
		\end{table}
	}{0.49}{
		\begin{table}[h]
			\scalebox{0.8}{
			\begin{tabular}{| c | c | c |}
				\hline
				\multicolumn{3}{| c |}{\textbf{HMM} [NER]}
				\\ \hline\hline
				\textbf{Features}		&	\textbf{F1 score}		& 	\textbf{Acc (w / s)}
				\\ \hline\hline
				word sequence			&	0.946				& 	0.946 / 0.523
				\\ \hline
			\end{tabular}}
		\end{table}
	}
	\tiny \textbf{Legend:} \\
	\textbf{w}: word, \textbf{l}: lowercase word, \textbf{s}: stem, \textbf{uwf}: unknown word features,
	\textbf{bf}: bigram features, \textbf{pos}: part of speech tags
\end{frame}


% Results (Ctd.)
\begin{frame}{Results (Ctd.)}{Named Entity Recognition}
	\begin{table}[h]
		\scalebox{0.8}{
		\begin{tabular}{| c |  c | c |}
			\hline
			\multicolumn{3}{| c |}{\textbf{CRF} [NER]}
			\\ \hline\hline
			\textbf{Features}		&	\textbf{F1 score}		& 	\textbf{Accuracy (w / s)}
			\\ \hline\hline
			w, l, s	 			& 	0.974				&	0.974 / 0.694
			\\ \hline
			w, l, s, uwf 			& 	0.974				& 	0.974 / 0.694
			\\ \hline
			w, l, s, uwf, pos			& 						&
			\\ \hline
			w, l, s, uwf, pos, bf		& 						&
			\\ \hline
		\end{tabular}}
	\end{table}
	\tiny \textbf{Legend:} \\
	\textbf{w}: word, \textbf{l}: lowercase word, \textbf{s}: stem, \textbf{uwf}: unknown word features,
	\textbf{bf}: bigram features, \textbf{pos}: part of speech tags
\end{frame}


% Comparison
\begin{frame}{Result Comparison}{}
	\begin{itemize}
		\item Naive Bayes confuses \texttt{per-ord} with \texttt{eve-ord}, but HMM does not \\
			$\Rightarrow$ context knowledge!
		\item Naive Bayes predicts \texttt{per-tit} very often
		\item Naive Bayes confuses \texttt{tim-clo} and \texttt{tim-dat} often
		\item HMM incorrectly predicts \texttt{DET} tag (POS) very often
		\item HMM incorrectly predicts \texttt{O} tag (NER) very often
	\end{itemize}
\end{frame}


% What we have learned...
\begin{frame}{What we have learned...}{}
	\begin{itemize}
		\item Feature engineering is 'dirty work' but crucial for later performance
		\item POS tagging
		\begin{itemize}
			\item Likely transitions: \texttt{MD} $\Rightarrow$ \texttt{VB}; \texttt{NNS} $\Rightarrow$ \texttt{VBP}
			\item Unlikely transitions: \texttt{DT} $\Rightarrow$ \texttt{DT}; \texttt{VBD} $\Rightarrow$ \texttt{VBD}
		\end{itemize}
		\item NER
		\begin{itemize}
			\item Likely transitions: \texttt{} $\Rightarrow$ \texttt{}
			\item Unlikely transitions: \texttt{} $\Rightarrow$ \texttt{}
		\end{itemize}
	\end{itemize}
\end{frame}


% Thank you
%______________________________________________________________________
\makethanks

\end{document}